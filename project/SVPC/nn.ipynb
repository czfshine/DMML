{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用户价值预测\n",
    "* 根据各个参数预测用户的价值\n",
    "\n",
    "[kggle链接](https://www.kaggle.com/c/santander-value-prediction-challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing, model_selection, metrics\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows and columns :  (4459, 4993)\n",
      "Test rows and columns :  (49342, 4992)\n"
     ]
    }
   ],
   "source": [
    "DATAPATH=\"D:/dataset/SVPC/\"\n",
    "train_df = pd.read_csv(DATAPATH+\"train.csv\")\n",
    "test_df = pd.read_csv(DATAPATH+\"test.csv\")\n",
    "print(\"Train rows and columns : \", train_df.shape)\n",
    "print(\"Test rows and columns : \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_df = train_df.nunique().reset_index()\n",
    "unique_df.columns = [\"col_name\", \"unique_count\"]\n",
    "constant_df = unique_df[unique_df[\"unique_count\"]==1]\n",
    "constant_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the X and y variables for building model ###\n",
    "train_X = train_df.drop(constant_df.col_name.tolist() + [\"ID\", \"target\"], axis=1)\n",
    "test_X = test_df.drop(constant_df.col_name.tolist() + [\"ID\"], axis=1)\n",
    "train_y =train_df[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.log1p(train_X.values)\n",
    "Y = np.log1p(train_y)\n",
    "T = np.log1p(test_X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\envs\\kaggle180629\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, input_dim=4735, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  \n",
      "C:\\anaconda\\envs\\kaggle180629\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, activation=\"softplus\", kernel_initializer=\"normal\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\anaconda\\envs\\kaggle180629\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X.shape[1], init='normal', activation='relu'))\n",
    "model.add(Dense(256, init='normal', activation='softplus'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, init='normal',activation='relu'))\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 521\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 32)                151552    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 160,257\n",
      "Trainable params: 160,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4013 samples, validate on 446 samples\n",
      "Epoch 1/128\n",
      "4013/4013 [==============================] - 1s 293us/step - loss: 187.8263 - val_loss: 157.5494\n",
      "Epoch 2/128\n",
      "4013/4013 [==============================] - 1s 132us/step - loss: 161.8372 - val_loss: 130.5559\n",
      "Epoch 3/128\n",
      "4013/4013 [==============================] - 1s 132us/step - loss: 134.0880 - val_loss: 116.9991\n",
      "Epoch 4/128\n",
      "4013/4013 [==============================] - 1s 130us/step - loss: 115.6570 - val_loss: 119.0616\n",
      "Epoch 5/128\n",
      "4013/4013 [==============================] - 1s 129us/step - loss: 111.5771 - val_loss: 116.5735\n",
      "Epoch 6/128\n",
      "4013/4013 [==============================] - 1s 129us/step - loss: 106.5499 - val_loss: 102.6616\n",
      "Epoch 7/128\n",
      "4013/4013 [==============================] - 1s 129us/step - loss: 96.4151 - val_loss: 86.2677\n",
      "Epoch 8/128\n",
      "4013/4013 [==============================] - 1s 130us/step - loss: 84.4143 - val_loss: 74.8328\n",
      "Epoch 9/128\n",
      "4013/4013 [==============================] - 1s 147us/step - loss: 75.4358 - val_loss: 68.3620\n",
      "Epoch 10/128\n",
      "4013/4013 [==============================] - 1s 129us/step - loss: 70.2519 - val_loss: 64.5593\n",
      "Epoch 11/128\n",
      "4013/4013 [==============================] - 1s 140us/step - loss: 66.7584 - val_loss: 61.3626\n",
      "Epoch 12/128\n",
      "4013/4013 [==============================] - 1s 133us/step - loss: 63.5297 - val_loss: 57.9208\n",
      "Epoch 13/128\n",
      "4013/4013 [==============================] - 1s 129us/step - loss: 59.9189 - val_loss: 54.2463\n",
      "Epoch 14/128\n",
      "4013/4013 [==============================] - 1s 142us/step - loss: 55.8053 - val_loss: 50.8210\n",
      "Epoch 15/128\n",
      "4013/4013 [==============================] - 1s 148us/step - loss: 52.1231 - val_loss: 48.0587\n",
      "Epoch 16/128\n",
      "4013/4013 [==============================] - 1s 130us/step - loss: 48.9011 - val_loss: 45.9055\n",
      "Epoch 17/128\n",
      "4013/4013 [==============================] - 1s 130us/step - loss: 46.2685 - val_loss: 43.8490\n",
      "Epoch 18/128\n",
      "4013/4013 [==============================] - 1s 129us/step - loss: 44.0499 - val_loss: 41.5220\n",
      "Epoch 19/128\n",
      "4013/4013 [==============================] - 1s 133us/step - loss: 41.2449 - val_loss: 39.1899\n",
      "Epoch 20/128\n",
      "4013/4013 [==============================] - 1s 129us/step - loss: 38.5137 - val_loss: 37.3575\n",
      "Epoch 21/128\n",
      "4013/4013 [==============================] - 1s 134us/step - loss: 36.1849 - val_loss: 36.1188\n",
      "Epoch 22/128\n",
      "4013/4013 [==============================] - 1s 140us/step - loss: 34.5578 - val_loss: 35.1577\n",
      "Epoch 23/128\n",
      "4013/4013 [==============================] - 1s 129us/step - loss: 33.3119 - val_loss: 34.0401\n",
      "Epoch 24/128\n",
      "4013/4013 [==============================] - 1s 140us/step - loss: 32.0206 - val_loss: 32.7092\n",
      "Epoch 25/128\n",
      "4013/4013 [==============================] - 1s 135us/step - loss: 30.8227 - val_loss: 31.3730\n",
      "Epoch 26/128\n",
      "4013/4013 [==============================] - 1s 129us/step - loss: 29.3020 - val_loss: 30.0386\n",
      "Epoch 27/128\n",
      "4013/4013 [==============================] - 1s 134us/step - loss: 27.7274 - val_loss: 28.6798\n",
      "Epoch 28/128\n",
      "4013/4013 [==============================] - 1s 139us/step - loss: 26.3008 - val_loss: 27.3810\n",
      "Epoch 29/128\n",
      "4013/4013 [==============================] - 1s 129us/step - loss: 24.9424 - val_loss: 26.2457\n",
      "Epoch 30/128\n",
      "4013/4013 [==============================] - 1s 144us/step - loss: 23.7825 - val_loss: 25.2812\n",
      "Epoch 31/128\n",
      "4013/4013 [==============================] - 1s 132us/step - loss: 22.7984 - val_loss: 24.4175\n",
      "Epoch 32/128\n",
      "4013/4013 [==============================] - 1s 131us/step - loss: 21.5914 - val_loss: 23.5826\n",
      "Epoch 33/128\n",
      "4013/4013 [==============================] - 1s 135us/step - loss: 20.7571 - val_loss: 22.7639\n",
      "Epoch 34/128\n",
      "4013/4013 [==============================] - 1s 139us/step - loss: 19.5907 - val_loss: 21.9951\n",
      "Epoch 35/128\n",
      "4013/4013 [==============================] - 1s 146us/step - loss: 18.6792 - val_loss: 21.3230\n",
      "Epoch 36/128\n",
      "4013/4013 [==============================] - 1s 130us/step - loss: 17.6732 - val_loss: 20.7513\n",
      "Epoch 37/128\n",
      "4013/4013 [==============================] - 1s 130us/step - loss: 16.8924 - val_loss: 20.2318\n",
      "Epoch 38/128\n",
      "4013/4013 [==============================] - 1s 133us/step - loss: 16.1164 - val_loss: 19.7078\n",
      "Epoch 39/128\n",
      "4013/4013 [==============================] - 1s 144us/step - loss: 15.4321 - val_loss: 19.1836\n",
      "Epoch 40/128\n",
      "4013/4013 [==============================] - 1s 133us/step - loss: 14.6029 - val_loss: 18.6822\n",
      "Epoch 41/128\n",
      "4013/4013 [==============================] - 1s 131us/step - loss: 14.0671 - val_loss: 18.1877\n",
      "Epoch 42/128\n",
      "4013/4013 [==============================] - 1s 138us/step - loss: 13.4114 - val_loss: 17.7259\n",
      "Epoch 43/128\n",
      "4013/4013 [==============================] - 1s 145us/step - loss: 12.7814 - val_loss: 17.3199\n",
      "Epoch 44/128\n",
      "4013/4013 [==============================] - 1s 130us/step - loss: 12.2381 - val_loss: 16.9638\n",
      "Epoch 45/128\n",
      "4013/4013 [==============================] - 1s 143us/step - loss: 11.7266 - val_loss: 16.6409\n",
      "Epoch 46/128\n",
      "4013/4013 [==============================] - 1s 131us/step - loss: 11.2470 - val_loss: 16.3281\n",
      "Epoch 47/128\n",
      "4013/4013 [==============================] - 1s 135us/step - loss: 10.6804 - val_loss: 16.0162\n",
      "Epoch 48/128\n",
      "4013/4013 [==============================] - 1s 141us/step - loss: 10.3042 - val_loss: 15.7002\n",
      "Epoch 49/128\n",
      "4013/4013 [==============================] - 1s 141us/step - loss: 9.8575 - val_loss: 15.3966\n",
      "Epoch 50/128\n",
      "4013/4013 [==============================] - 1s 133us/step - loss: 9.4833 - val_loss: 15.1086\n",
      "Epoch 51/128\n",
      "4013/4013 [==============================] - 1s 140us/step - loss: 9.0604 - val_loss: 14.8379\n",
      "Epoch 52/128\n",
      "4013/4013 [==============================] - 1s 130us/step - loss: 8.8592 - val_loss: 14.5897\n",
      "Epoch 53/128\n",
      "4013/4013 [==============================] - 1s 133us/step - loss: 8.3619 - val_loss: 14.3597\n",
      "Epoch 54/128\n",
      "4013/4013 [==============================] - 1s 138us/step - loss: 8.0006 - val_loss: 14.1453\n",
      "Epoch 55/128\n",
      "4013/4013 [==============================] - 1s 138us/step - loss: 7.7940 - val_loss: 13.9223\n",
      "Epoch 56/128\n",
      "4013/4013 [==============================] - 1s 136us/step - loss: 7.4882 - val_loss: 13.6872\n",
      "Epoch 57/128\n",
      "4013/4013 [==============================] - 1s 134us/step - loss: 7.2361 - val_loss: 13.4494\n",
      "Epoch 58/128\n",
      "4013/4013 [==============================] - 1s 135us/step - loss: 6.8926 - val_loss: 13.2294\n",
      "Epoch 59/128\n",
      "4013/4013 [==============================] - 1s 132us/step - loss: 6.7433 - val_loss: 13.0243\n",
      "Epoch 60/128\n",
      "4013/4013 [==============================] - 1s 136us/step - loss: 6.4114 - val_loss: 12.8382\n",
      "Epoch 61/128\n",
      "4013/4013 [==============================] - 1s 134us/step - loss: 6.2477 - val_loss: 12.6622\n",
      "Epoch 62/128\n",
      "4013/4013 [==============================] - 1s 139us/step - loss: 6.0266 - val_loss: 12.4900\n",
      "Epoch 63/128\n",
      "4013/4013 [==============================] - 1s 141us/step - loss: 5.8164 - val_loss: 12.3120\n",
      "Epoch 64/128\n",
      "4013/4013 [==============================] - 1s 142us/step - loss: 5.6051 - val_loss: 12.1400\n",
      "Epoch 65/128\n",
      "4013/4013 [==============================] - 1s 148us/step - loss: 5.4774 - val_loss: 11.9842\n",
      "Epoch 66/128\n",
      "4013/4013 [==============================] - 1s 145us/step - loss: 5.2022 - val_loss: 11.8500\n",
      "Epoch 67/128\n",
      "4013/4013 [==============================] - 1s 148us/step - loss: 5.0654 - val_loss: 11.7323\n",
      "Epoch 68/128\n",
      "4013/4013 [==============================] - 1s 145us/step - loss: 4.9324 - val_loss: 11.6252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/128\n",
      "4013/4013 [==============================] - 1s 141us/step - loss: 4.7200 - val_loss: 11.5278\n",
      "Epoch 70/128\n",
      "4013/4013 [==============================] - 1s 153us/step - loss: 4.6174 - val_loss: 11.4338\n",
      "Epoch 71/128\n",
      "4013/4013 [==============================] - 1s 128us/step - loss: 4.4772 - val_loss: 11.3307\n",
      "Epoch 72/128\n",
      "4013/4013 [==============================] - 1s 128us/step - loss: 4.3491 - val_loss: 11.2210\n",
      "Epoch 73/128\n",
      "4013/4013 [==============================] - 1s 127us/step - loss: 4.2411 - val_loss: 11.1115\n",
      "Epoch 74/128\n",
      "4013/4013 [==============================] - 1s 127us/step - loss: 4.0921 - val_loss: 11.0154\n",
      "Epoch 75/128\n",
      "4013/4013 [==============================] - 1s 127us/step - loss: 3.9918 - val_loss: 10.9312\n",
      "Epoch 76/128\n",
      "4013/4013 [==============================] - 1s 129us/step - loss: 3.8978 - val_loss: 10.8495\n",
      "Epoch 77/128\n",
      "4013/4013 [==============================] - 1s 130us/step - loss: 3.7712 - val_loss: 10.7669\n",
      "Epoch 78/128\n",
      "4013/4013 [==============================] - 1s 125us/step - loss: 3.6857 - val_loss: 10.6796\n",
      "Epoch 79/128\n",
      "4013/4013 [==============================] - 1s 132us/step - loss: 3.5517 - val_loss: 10.5924\n",
      "Epoch 80/128\n",
      "4013/4013 [==============================] - 1s 127us/step - loss: 3.5055 - val_loss: 10.5065\n",
      "Epoch 81/128\n",
      "4013/4013 [==============================] - 1s 128us/step - loss: 3.3744 - val_loss: 10.4268\n",
      "Epoch 82/128\n",
      "4013/4013 [==============================] - 1s 128us/step - loss: 3.3020 - val_loss: 10.3562\n",
      "Epoch 83/128\n",
      "4013/4013 [==============================] - 1s 127us/step - loss: 3.2319 - val_loss: 10.2839\n",
      "Epoch 84/128\n",
      "4013/4013 [==============================] - 1s 127us/step - loss: 3.1575 - val_loss: 10.2275\n",
      "Epoch 85/128\n",
      "4013/4013 [==============================] - 1s 129us/step - loss: 3.0300 - val_loss: 10.1808\n",
      "Epoch 86/128\n",
      "4013/4013 [==============================] - 1s 145us/step - loss: 2.9797 - val_loss: 10.1406\n",
      "Epoch 87/128\n",
      "4013/4013 [==============================] - 1s 141us/step - loss: 2.8931 - val_loss: 10.0987\n",
      "Epoch 88/128\n",
      "4013/4013 [==============================] - 1s 144us/step - loss: 2.8234 - val_loss: 10.0435\n",
      "Epoch 89/128\n",
      "4013/4013 [==============================] - 1s 145us/step - loss: 2.7812 - val_loss: 9.9760\n",
      "Epoch 90/128\n",
      "4013/4013 [==============================] - 1s 136us/step - loss: 2.7212 - val_loss: 9.9213\n",
      "Epoch 91/128\n",
      "4013/4013 [==============================] - 1s 140us/step - loss: 2.6553 - val_loss: 9.8871\n",
      "Epoch 92/128\n",
      "4013/4013 [==============================] - 1s 136us/step - loss: 2.5391 - val_loss: 9.8587\n",
      "Epoch 93/128\n",
      "4013/4013 [==============================] - 1s 138us/step - loss: 2.5385 - val_loss: 9.8293\n",
      "Epoch 94/128\n",
      "4013/4013 [==============================] - 1s 139us/step - loss: 2.4385 - val_loss: 9.7894\n",
      "Epoch 95/128\n",
      "4013/4013 [==============================] - 1s 139us/step - loss: 2.4298 - val_loss: 9.7353\n",
      "Epoch 96/128\n",
      "4013/4013 [==============================] - 1s 138us/step - loss: 2.4009 - val_loss: 9.6804\n",
      "Epoch 97/128\n",
      "4013/4013 [==============================] - 1s 139us/step - loss: 2.3152 - val_loss: 9.6306\n",
      "Epoch 98/128\n",
      "4013/4013 [==============================] - 1s 140us/step - loss: 2.2768 - val_loss: 9.5997\n",
      "Epoch 99/128\n",
      "4013/4013 [==============================] - 1s 138us/step - loss: 2.2237 - val_loss: 9.5906\n",
      "Epoch 100/128\n",
      "4013/4013 [==============================] - 1s 140us/step - loss: 2.1735 - val_loss: 9.5708\n",
      "Epoch 101/128\n",
      "4013/4013 [==============================] - 1s 141us/step - loss: 2.1551 - val_loss: 9.5412\n",
      "Epoch 102/128\n",
      "4013/4013 [==============================] - 1s 140us/step - loss: 2.0564 - val_loss: 9.5023\n",
      "Epoch 103/128\n",
      "4013/4013 [==============================] - 1s 137us/step - loss: 2.0684 - val_loss: 9.4662\n",
      "Epoch 104/128\n",
      "4013/4013 [==============================] - 1s 138us/step - loss: 1.9792 - val_loss: 9.4433\n",
      "Epoch 105/128\n",
      "4013/4013 [==============================] - 1s 142us/step - loss: 1.9510 - val_loss: 9.4196\n",
      "Epoch 106/128\n",
      "4013/4013 [==============================] - 1s 135us/step - loss: 1.9159 - val_loss: 9.4037\n",
      "Epoch 107/128\n",
      "4013/4013 [==============================] - 1s 142us/step - loss: 1.9548 - val_loss: 9.3730\n",
      "Epoch 108/128\n",
      "4013/4013 [==============================] - 1s 141us/step - loss: 1.8627 - val_loss: 9.3389\n",
      "Epoch 109/128\n",
      "4013/4013 [==============================] - 1s 142us/step - loss: 1.8600 - val_loss: 9.2989\n",
      "Epoch 110/128\n",
      "4013/4013 [==============================] - 1s 148us/step - loss: 1.8048 - val_loss: 9.2649\n",
      "Epoch 111/128\n",
      "4013/4013 [==============================] - 1s 142us/step - loss: 1.8175 - val_loss: 9.2407\n",
      "Epoch 112/128\n",
      "4013/4013 [==============================] - 1s 138us/step - loss: 1.7204 - val_loss: 9.2282\n",
      "Epoch 113/128\n",
      "4013/4013 [==============================] - 1s 150us/step - loss: 1.6635 - val_loss: 9.2145\n",
      "Epoch 114/128\n",
      "4013/4013 [==============================] - 1s 148us/step - loss: 1.6965 - val_loss: 9.1922\n",
      "Epoch 115/128\n",
      "4013/4013 [==============================] - 1s 145us/step - loss: 1.6865 - val_loss: 9.1734\n",
      "Epoch 116/128\n",
      "4013/4013 [==============================] - 1s 140us/step - loss: 1.6447 - val_loss: 9.1626\n",
      "Epoch 117/128\n",
      "4013/4013 [==============================] - 1s 150us/step - loss: 1.5589 - val_loss: 9.1452\n",
      "Epoch 118/128\n",
      "4013/4013 [==============================] - 1s 148us/step - loss: 1.5567 - val_loss: 9.1275\n",
      "Epoch 119/128\n",
      "4013/4013 [==============================] - 1s 136us/step - loss: 1.5602 - val_loss: 9.1080\n",
      "Epoch 120/128\n",
      "4013/4013 [==============================] - 1s 132us/step - loss: 1.5304 - val_loss: 9.0775\n",
      "Epoch 121/128\n",
      "4013/4013 [==============================] - 1s 132us/step - loss: 1.4771 - val_loss: 9.0758\n",
      "Epoch 122/128\n",
      "4013/4013 [==============================] - 1s 129us/step - loss: 1.4703 - val_loss: 9.0666\n",
      "Epoch 123/128\n",
      "4013/4013 [==============================] - 1s 140us/step - loss: 1.4704 - val_loss: 9.0402\n",
      "Epoch 124/128\n",
      "4013/4013 [==============================] - 1s 130us/step - loss: 1.4276 - val_loss: 9.0086\n",
      "Epoch 125/128\n",
      "4013/4013 [==============================] - 1s 139us/step - loss: 1.4027 - val_loss: 8.9810\n",
      "Epoch 126/128\n",
      "4013/4013 [==============================] - 1s 143us/step - loss: 1.4180 - val_loss: 8.9766\n",
      "Epoch 127/128\n",
      "4013/4013 [==============================] - 1s 137us/step - loss: 1.3712 - val_loss: 8.9819\n",
      "Epoch 128/128\n",
      "4013/4013 [==============================] - 1s 141us/step - loss: 1.3497 - val_loss: 8.9729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8375130590776207"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "h=model.fit(X,Y,batch_size=X.shape[1],epochs=128,validation_split=0.1,shuffle=True)\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "mean_squared_log_error(np.expm1(model.predict(X)).reshape(X.shape[0]),train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=pd.DataFrame({\"ID\":test_df[\"ID\"],\"target\":np.expm1(model.predict(T).reshape(T.shape[0]))})\n",
    "p.to_csv(\"nn2l.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h.history[\"loss\"])\n",
    "plt.plot(h.history[\"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , 17.01895271, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log1p(test_X.values[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [157.54937744140625,\n",
       "  130.55587768554688,\n",
       "  116.99905395507812,\n",
       "  119.06163024902344,\n",
       "  116.57350158691406,\n",
       "  102.66157531738281,\n",
       "  86.26773071289062,\n",
       "  74.8327865600586,\n",
       "  68.36202239990234,\n",
       "  64.55934143066406,\n",
       "  61.362552642822266,\n",
       "  57.92080307006836,\n",
       "  54.24630355834961,\n",
       "  50.821041107177734,\n",
       "  48.05865478515625,\n",
       "  45.90553283691406,\n",
       "  43.849037170410156,\n",
       "  41.521976470947266,\n",
       "  39.18989562988281,\n",
       "  37.357452392578125,\n",
       "  36.11880874633789,\n",
       "  35.15766143798828,\n",
       "  34.040096282958984,\n",
       "  32.70922088623047,\n",
       "  31.372983932495117,\n",
       "  30.038576126098633,\n",
       "  28.679758071899414,\n",
       "  27.38099479675293,\n",
       "  26.245723724365234,\n",
       "  25.28117561340332,\n",
       "  24.417490005493164,\n",
       "  23.582582473754883,\n",
       "  22.76386833190918,\n",
       "  21.99513053894043,\n",
       "  21.322956085205078,\n",
       "  20.75128746032715,\n",
       "  20.231765747070312,\n",
       "  19.707809448242188,\n",
       "  19.183584213256836,\n",
       "  18.682191848754883,\n",
       "  18.187726974487305,\n",
       "  17.725921630859375,\n",
       "  17.319944381713867,\n",
       "  16.96379280090332,\n",
       "  16.640945434570312,\n",
       "  16.32813262939453,\n",
       "  16.016239166259766,\n",
       "  15.700178146362305,\n",
       "  15.396550178527832,\n",
       "  15.108621597290039,\n",
       "  14.837862968444824,\n",
       "  14.589653015136719,\n",
       "  14.359654426574707,\n",
       "  14.145262718200684,\n",
       "  13.922313690185547,\n",
       "  13.68721866607666,\n",
       "  13.449422836303711,\n",
       "  13.229401588439941,\n",
       "  13.024258613586426,\n",
       "  12.838245391845703,\n",
       "  12.662211418151855,\n",
       "  12.489974975585938,\n",
       "  12.31201171875,\n",
       "  12.139958381652832,\n",
       "  11.984230041503906,\n",
       "  11.849959373474121,\n",
       "  11.73228931427002,\n",
       "  11.62517261505127,\n",
       "  11.527801513671875,\n",
       "  11.433810234069824,\n",
       "  11.33073902130127,\n",
       "  11.221034049987793,\n",
       "  11.111481666564941,\n",
       "  11.015423774719238,\n",
       "  10.931154251098633,\n",
       "  10.849467277526855,\n",
       "  10.76686954498291,\n",
       "  10.679586410522461,\n",
       "  10.59238052368164,\n",
       "  10.506464004516602,\n",
       "  10.426811218261719,\n",
       "  10.356210708618164,\n",
       "  10.283930778503418,\n",
       "  10.227478981018066,\n",
       "  10.180840492248535,\n",
       "  10.140639305114746,\n",
       "  10.09874439239502,\n",
       "  10.043543815612793,\n",
       "  9.976032257080078,\n",
       "  9.921308517456055,\n",
       "  9.887076377868652,\n",
       "  9.858717918395996,\n",
       "  9.829324722290039,\n",
       "  9.78942584991455,\n",
       "  9.735336303710938,\n",
       "  9.680381774902344,\n",
       "  9.630584716796875,\n",
       "  9.599678039550781,\n",
       "  9.59056568145752,\n",
       "  9.570760726928711,\n",
       "  9.541176795959473,\n",
       "  9.502301216125488,\n",
       "  9.466198921203613,\n",
       "  9.443283081054688,\n",
       "  9.419610977172852,\n",
       "  9.403706550598145,\n",
       "  9.37302303314209,\n",
       "  9.33890151977539,\n",
       "  9.298874855041504,\n",
       "  9.264892578125,\n",
       "  9.240692138671875,\n",
       "  9.228221893310547,\n",
       "  9.214472770690918,\n",
       "  9.192194938659668,\n",
       "  9.173416137695312,\n",
       "  9.162629127502441,\n",
       "  9.145203590393066,\n",
       "  9.127513885498047,\n",
       "  9.107964515686035,\n",
       "  9.077515602111816,\n",
       "  9.075756072998047,\n",
       "  9.06656265258789,\n",
       "  9.040172576904297,\n",
       "  9.008611679077148,\n",
       "  8.981000900268555,\n",
       "  8.976587295532227,\n",
       "  8.9818754196167,\n",
       "  8.972919464111328],\n",
       " 'loss': [187.82630920410156,\n",
       "  161.837158203125,\n",
       "  134.08802795410156,\n",
       "  115.65702056884766,\n",
       "  111.57706451416016,\n",
       "  106.54991912841797,\n",
       "  96.41508483886719,\n",
       "  84.41432189941406,\n",
       "  75.43583679199219,\n",
       "  70.25192260742188,\n",
       "  66.75843811035156,\n",
       "  63.529727935791016,\n",
       "  59.918888092041016,\n",
       "  55.805320739746094,\n",
       "  52.12311935424805,\n",
       "  48.90109634399414,\n",
       "  46.26850128173828,\n",
       "  44.04985427856445,\n",
       "  41.2448616027832,\n",
       "  38.513736724853516,\n",
       "  36.18491744995117,\n",
       "  34.557838439941406,\n",
       "  33.31187438964844,\n",
       "  32.020565032958984,\n",
       "  30.822731018066406,\n",
       "  29.301956176757812,\n",
       "  27.727371215820312,\n",
       "  26.30076789855957,\n",
       "  24.942407608032227,\n",
       "  23.782487869262695,\n",
       "  22.798429489135742,\n",
       "  21.59140968322754,\n",
       "  20.757062911987305,\n",
       "  19.590654373168945,\n",
       "  18.67923355102539,\n",
       "  17.673206329345703,\n",
       "  16.892383575439453,\n",
       "  16.116371154785156,\n",
       "  15.43212604522705,\n",
       "  14.602940559387207,\n",
       "  14.06714916229248,\n",
       "  13.411412239074707,\n",
       "  12.781352043151855,\n",
       "  12.238056182861328,\n",
       "  11.726618766784668,\n",
       "  11.2470064163208,\n",
       "  10.68038272857666,\n",
       "  10.304227828979492,\n",
       "  9.85752010345459,\n",
       "  9.483282089233398,\n",
       "  9.0603609085083,\n",
       "  8.859175682067871,\n",
       "  8.361875534057617,\n",
       "  8.00055980682373,\n",
       "  7.7939887046813965,\n",
       "  7.488248348236084,\n",
       "  7.23614501953125,\n",
       "  6.892636299133301,\n",
       "  6.743307590484619,\n",
       "  6.411393642425537,\n",
       "  6.2476911544799805,\n",
       "  6.026552200317383,\n",
       "  5.816363334655762,\n",
       "  5.605105876922607,\n",
       "  5.477409362792969,\n",
       "  5.202177047729492,\n",
       "  5.065399169921875,\n",
       "  4.932416915893555,\n",
       "  4.719971656799316,\n",
       "  4.617406845092773,\n",
       "  4.477163314819336,\n",
       "  4.349064826965332,\n",
       "  4.24112606048584,\n",
       "  4.092128276824951,\n",
       "  3.9918181896209717,\n",
       "  3.8977935314178467,\n",
       "  3.7712180614471436,\n",
       "  3.6857099533081055,\n",
       "  3.551680088043213,\n",
       "  3.505486488342285,\n",
       "  3.37439227104187,\n",
       "  3.301990032196045,\n",
       "  3.2318737506866455,\n",
       "  3.1575353145599365,\n",
       "  3.0299785137176514,\n",
       "  2.979673385620117,\n",
       "  2.893101215362549,\n",
       "  2.823406219482422,\n",
       "  2.7811975479125977,\n",
       "  2.72121262550354,\n",
       "  2.6553308963775635,\n",
       "  2.5391123294830322,\n",
       "  2.538451910018921,\n",
       "  2.438480854034424,\n",
       "  2.4298174381256104,\n",
       "  2.4008944034576416,\n",
       "  2.315208911895752,\n",
       "  2.2768020629882812,\n",
       "  2.2237462997436523,\n",
       "  2.173468589782715,\n",
       "  2.155094623565674,\n",
       "  2.056401252746582,\n",
       "  2.0684053897857666,\n",
       "  1.97915780544281,\n",
       "  1.9510278701782227,\n",
       "  1.9158955812454224,\n",
       "  1.9547849893569946,\n",
       "  1.8627115488052368,\n",
       "  1.8600199222564697,\n",
       "  1.8048166036605835,\n",
       "  1.817517638206482,\n",
       "  1.7204391956329346,\n",
       "  1.6634794473648071,\n",
       "  1.6965439319610596,\n",
       "  1.6865479946136475,\n",
       "  1.644749641418457,\n",
       "  1.558918833732605,\n",
       "  1.5567359924316406,\n",
       "  1.5601941347122192,\n",
       "  1.5304248332977295,\n",
       "  1.4770569801330566,\n",
       "  1.4703108072280884,\n",
       "  1.4703741073608398,\n",
       "  1.4275707006454468,\n",
       "  1.4026596546173096,\n",
       "  1.4180183410644531,\n",
       "  1.3712481260299683,\n",
       "  1.3496872186660767]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
